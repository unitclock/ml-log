{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import psutil\n",
    "import platform\n",
    "import shutil\n",
    "import pynvml\n",
    "import multiprocessing\n",
    "import yaml\n",
    "from functools import wraps\n",
    "import csv\n",
    "import statistics\n",
    "import sys\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single(cls):\n",
    "    _instance = {}\n",
    "    @wraps(cls)\n",
    "    def _single(*args,**kwargs):\n",
    "        # nonlocal _instance\n",
    "        if cls not in _instance :\n",
    "            _instance[cls] = cls(*args,**kwargs) \n",
    "        else:\n",
    "            pass\n",
    "        return _instance[cls]\n",
    "    return _single\n",
    "\n",
    "def run_as_daemon(func):\n",
    "    @wraps(func)\n",
    "    def _process(*arg,**kwargs):\n",
    "        p = multiprocessing.Process(target=func,args=arg,kwargs=kwargs,daemon=True)\n",
    "        p.start()\n",
    "        return p\n",
    "    return _process\n",
    "\n",
    "def get_os_info() ->dict:\n",
    "\n",
    "    device = get_gpu_list()\n",
    "    try:\n",
    "        info = {\n",
    "                \"hostname\":platform.node(),\n",
    "                \"platform\":platform.platform(),\n",
    "                \"system\":platform.system(),\n",
    "                \"python_version\":platform.python_version(),\n",
    "                \"architecture\":platform.architecture()[0],\n",
    "                \"processor\":platform.processor(),\n",
    "                \"uname\":str(platform.uname()),\n",
    "                \"cpu_logical_count\":psutil.cpu_count(),\n",
    "                \"cpu_count\": psutil.cpu_count(logical=False),\n",
    "                \"total_memory\": psutil.virtual_memory().total /100000,\n",
    "                \"active_memory\": psutil.virtual_memory().active /100000,\n",
    "                \"available_memory\": psutil.virtual_memory().available /100000,\n",
    "                \"total_swap_memory\":psutil.swap_memory().total /100000,\n",
    "                \"nvidia_gpu_info\":str(device),\n",
    "                \"python_path\":sys.executable,\n",
    "                \"run_path\":os.getcwd()\n",
    "        }\n",
    "    except:\n",
    "        raise BaseException(\"系统信息采集失败\")\n",
    "\n",
    "    return info\n",
    "\n",
    "@run_as_daemon\n",
    "def watch_cpu(path:str):\n",
    "    os.makedirs(path,mode=0o777,exist_ok=True)\n",
    "    sleep_time = 5\n",
    "    cut_time =1800\n",
    "    i =0\n",
    "    count = 0\n",
    "    while True:\n",
    "        with open(f\"{path}/cpu-{count}.log\",\"a\") as f:\n",
    "            while True:\n",
    "                cpu_percent = psutil.cpu_percent()\n",
    "                memory = psutil.virtual_memory().used\n",
    "                f.write(str({\"time\":time.strftime('%Y-%m-%d %X', time.localtime()),\"cpu_percent\":cpu_percent,\"memory\":memory})+\"\\n\")\n",
    "                f.flush()\n",
    "                time.sleep(sleep_time)\n",
    "                i+=1\n",
    "                if i ==(cut_time/sleep_time):\n",
    "                    i =0\n",
    "                    break\n",
    "        count +=1\n",
    "        continue\n",
    "    \n",
    "def save_dict_to_json(dict_value:dict , save_path:str) ->None:\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.write(json.dumps(dict_value, indent=2))\n",
    "        file.flush()\n",
    "    return\n",
    "\n",
    "def save_dict_to_yaml(dict_value: dict, save_path: str):\n",
    "    with open(save_path, 'w') as file:\n",
    "        file.write(yaml.dump(dict_value, allow_unicode=True))\n",
    "        file.flush()\n",
    "    return\n",
    "\n",
    "def read_yaml_to_dict(yaml_path: str):\n",
    "    with open(yaml_path) as file:\n",
    "        dict_value = yaml.load(file.read(), Loader=yaml.FullLoader)\n",
    "        return dict_value\n",
    "    \n",
    "def save_list_to_csv(data_list:list, output_file:str)->None:\n",
    "    headers = set()\n",
    "    for item in data_list:\n",
    "        headers.update(item.keys())\n",
    "\n",
    "    with open(output_file, 'w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        \n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        for item in data_list:\n",
    "            row = [item.get(key, '') for key in headers]\n",
    "            writer.writerow(row)\n",
    "    return\n",
    "\n",
    "@run_as_daemon\n",
    "def watch_gpu(path:str)->None:\n",
    "        os.makedirs(path,mode=0o777,exist_ok=True)\n",
    "        pynvml.nvmlInit()\n",
    "        sleep_time =5\n",
    "        device_count = pynvml.nvmlDeviceGetCount()\n",
    "        i =0\n",
    "        count = 0\n",
    "        while True:\n",
    "            with open(f\"{path}/gpu-{count}.log\",\"a\") as f:\n",
    "                while True:\n",
    "                    device_status =[]\n",
    "\n",
    "                    for i in range(device_count):\n",
    "                        handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "                        gpu_percent = pynvml.nvmlDeviceGetUtilizationRates(handle)\n",
    "                        gpu_memory = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                        status = {\"time\":time.strftime('%Y-%m-%d %X', time.localtime()),\"gpu_percent\":gpu_percent.gpu,\"gpu_memory\":gpu_memory.used}\n",
    "                        device_status.append(status)\n",
    "                    f.write(str(device_status)+\"\\n\")\n",
    "                    f.flush()\n",
    "                    time.sleep(sleep_time)\n",
    "                    i+=1\n",
    "                    if i == 1800/sleep_time:\n",
    "                        i = 0\n",
    "                        break\n",
    "                count+=1\n",
    "                continue\n",
    "\n",
    "def is_process_running(main_pid:int) ->bool:\n",
    "    try:\n",
    "        ps = psutil.Process(pid=main_pid)\n",
    "        return ps.is_running\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def save_conda_info(path:str) ->bool:\n",
    "    try:\n",
    "        result = subprocess.run(['conda', 'list'], capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "        with open(f\"{path}/conda.info\",\"a\") as file:\n",
    "                file.write(output)\n",
    "                file.flush()\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def get_gpu_list() ->list:\n",
    "    device_list =[]\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        device_count=pynvml.nvmlDeviceGetCount()\n",
    "\n",
    "        for i in range(device_count):\n",
    "            handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "            device_list.append(str(pynvml.nvmlDeviceGetName(handle)))\n",
    "    except:\n",
    "        print(\"未获取到Nvidia显卡信息 \\n\")\n",
    "    return device_list\n",
    "\n",
    "def has_multiple_keys(dictionary:dict, *keys):\n",
    "    return set(keys).issubset(dictionary.keys())\n",
    "\n",
    "\n",
    "\n",
    "def get_init_trainning_status()->dict:\n",
    "    return {\"epoch\":[],\"next_start_at\":0,\"count\":0}\n",
    "\n",
    "def get_process_pid() -> int:\n",
    "    return os.getpid()\n",
    "\n",
    "def get_all_recorded_element(data)->list:\n",
    "    elemet_list = []\n",
    "    for d in data :\n",
    "        elemet_list.extend(list(d.keys()))\n",
    "    result = list(set(elemet_list))\n",
    "    return result\n",
    "    \n",
    "def quick_analysis(status:list) ->dict:\n",
    "    result = {}\n",
    "    element_list = get_all_recorded_element(status)\n",
    "    for e in element_list:\n",
    "        result[e] = {}\n",
    "        origin_list = []\n",
    "        for s in status:\n",
    "            if e in s.keys():\n",
    "                origin_list.append(s[e])\n",
    "        result[e][\"max\"] = max(origin_list)\n",
    "        result[e][\"min\"] = min(origin_list)\n",
    "        result[e][\"viriance\"]=statistics.variance(origin_list)\n",
    "        result[e][\"stdev\"]=statistics.stdev(origin_list)\n",
    "        result[e][\"avg\"] = statistics.mean(origin_list)\n",
    "\n",
    "    return result\n",
    "\n",
    "def format_time() ->str:\n",
    "    return time.strftime(\"%Y-%m-%d %X\", time.localtime())\n",
    "\n",
    "def timestamp() ->str:\n",
    "    return time.strftime(\"%Y%m%d%H%M%S\", time.localtime())\n",
    "                \n",
    "def copy_file_to_dir(srcfile,dstpath):                       # 复制函数\n",
    "    if not os.path.isfile(srcfile):\n",
    "        print (\"%s not exist!\"%(srcfile))\n",
    "    else:\n",
    "        fpath,fname=os.path.split(srcfile)             # 分离文件名和路径\n",
    "        if not os.path.exists(dstpath):\n",
    "            os.makedirs(dstpath)                       # 创建路径\n",
    "        shutil.copy(srcfile, dstpath + fname)          # 复制文件\n",
    "\n",
    "def get_experiment_id() -> str:\n",
    "\n",
    "    digits = [str(random.randint(0, 9)) for _ in range(15)]\n",
    "\n",
    "    result = \"\".join(digits)\n",
    "    return  result \n",
    "    \n",
    "def api(url:str,data:dict) ->dict:\n",
    "    header = {'Content-Type': 'application/json'}\n",
    "    resp = requests.post(url=url,headers=header,json=data)\n",
    "    print(f\"{format_time()} {data} {url}\")\n",
    "    msg =dict(resp.json())\n",
    "    print(f\"{format_time()} {msg} \")\n",
    "    return msg\n",
    "    \n",
    "def append_fo_file(path:str,sth:str):\n",
    "    with open(path,\"a\") as file:\n",
    "            file.write(sth)\n",
    "            file.flush()\n",
    "    return    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewLogger(conf:dict,info:dict):\n",
    "    log = Logger(config=conf)\n",
    "    log.Start(info=info)\n",
    "    return log\n",
    "\n",
    "\n",
    "class Printer():\n",
    "        def __init__(self,run_path:str) ->None:\n",
    "            if os.path.exists(run_path):\n",
    "                self.__location = run_path\n",
    "                append_fo_file(self.__location,f\"console init {format_time()}\")\n",
    "            return\n",
    "        \n",
    "        def Print(self,sth:str):\n",
    "            append_fo_file(self.__location,sth=sth)\n",
    "            return\n",
    "        \n",
    "# @single\n",
    "class Logger():\n",
    "    def __init__(self,config:dict) -> None:\n",
    "\n",
    "        if not has_multiple_keys(config, 'access_token', 'project',\"description\",\"experiment_name\"):\n",
    "            raise BaseException(\"缺失启动信息,请补充config参数: access_token project description experiment ;可选配置项: repository_id\")\n",
    "        config[\"experiment_id\"] = get_experiment_id()\n",
    "        self.__config = config\n",
    "        self.__config[\"experiment_name\"] = f'{self.__config[\"experiment_name\"]}-{timestamp()}'\n",
    "        self.__verify_my_client()\n",
    "        self.__save_config()\n",
    "\n",
    "        self.__trainning_status  = get_init_trainning_status()\n",
    "        return\n",
    "\n",
    "    def Print(self,sth:str):\n",
    "        save_path =f\"{self.__location}/{self.__runid}/console.log\"\n",
    "        append_fo_file(path=save_path,sth=sth)            \n",
    "        pass\n",
    "\n",
    "        \n",
    "    def __verify_my_client(self,host=\"127.0.0.1\") ->None:\n",
    "\n",
    "        self.__api_load_save_path = f\"http://{host}:5560/ml_client/client/loadSavePath\"\n",
    "        self.__api_notice_experiment = f\"http://{host}:5560/ml_client/client/noticeExperiment\"\n",
    "        self.__api_notice_run = f\"http://{host}:5560/ml_client/client/noticeRun\"\n",
    "\n",
    "        try:\n",
    "\n",
    "            send_data={}\n",
    "            send_data[\"userToken\"] = self.__config[\"access_token\"]\n",
    "            send_data[\"projectId\"] = self.__config[\"project\"]\n",
    "            send_data[\"description\"] = self.__config[\"description\"]\n",
    "            send_data[\"experimentName\"] = self.__config[\"experiment_name\"]\n",
    "            try:\n",
    "                send_data[\"repositoryId\"] = self.__config[\"repository_id\"]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            msg =api(url=self.__api_load_save_path,data=send_data)\n",
    "            if not msg[\"code\"] == 200:\n",
    "                raise ConnectionError\n",
    "            self.__location = msg[\"data\"]\n",
    "        except:\n",
    "            raise ConnectionError\n",
    "        else:\n",
    "            self.__location = f\"{self.__location}/{self.__config['experiment_id']}\"\n",
    "            self.__savedir = f\"{self.__location}/code\"\n",
    "            self.__codedir = os.getcwd()\n",
    "            i = 0\n",
    "            self.__runid = f\"run-{i}\"\n",
    "\n",
    "        os.makedirs(f\"{self.__location}\",mode=0o777,exist_ok=True)\n",
    "        return\n",
    "\n",
    "    def __watcher(self) ->None:\n",
    "        cpu_dir =f\"{self.__location}/{self.__runid}/watcher/cpu\"\n",
    "        self.__watcher_cpu = watch_cpu(path=cpu_dir)\n",
    "        gpu_dir =f\"{self.__location}/{self.__runid}/watcher/gpu\"\n",
    "        self.__watcher_gpu = watch_gpu(path=gpu_dir)\n",
    "        return\n",
    "\n",
    "    def Start(self,info:dict) ->None:\n",
    "\n",
    "        if not save_conda_info(self.__location):\n",
    "            print(\"未采集到conda信息\")\n",
    "        try:\n",
    "            self.__osinfo = get_os_info()\n",
    "            \n",
    "            os_info_json_path =f\"{self.__location}/os_info.json\"\n",
    "            os_info_yaml_path =f\"{self.__location}/os_info.yaml\"\n",
    "\n",
    "            save_dict_to_json(self.__osinfo,os_info_json_path)\n",
    "            save_dict_to_yaml(self.__osinfo,os_info_yaml_path)\n",
    "            \n",
    "            super_arg_json_path = self.__location+\"/super_arg.json\"\n",
    "            super_arg_yaml_path = self.__location+\"/super_arg.yaml\"\n",
    "\n",
    "            save_dict_to_json(info,super_arg_json_path)\n",
    "            save_dict_to_yaml(info,super_arg_yaml_path)\n",
    "            \n",
    "            with open(f\"{self.__location}/start.tag\",mode=\"w\") as f:\n",
    "                f.write(f\"{format_time()} | {self.__runid}\\n\")\n",
    "                f.flush()\n",
    "            if os.system(\"pip freeze > requirements.txt\") == 0:\n",
    "                if os.path.exists(\"./requirements.txt\"):\n",
    "                    shutil.copy(\"./requirements.txt\",f\"{self.__location}\")    \n",
    "            send_data = {\n",
    "                        \"experimentId\":self.__config[\"experiment_id\"],\n",
    "                        \"status\":0\n",
    "                        }\n",
    "\n",
    "            self.__save_code()\n",
    "            resp = api(url=self.__api_notice_experiment,data=send_data)\n",
    "            if not resp[\"code\"] == 200:\n",
    "                raise ConnectionError      \n",
    "        except:\n",
    "            raise BaseException(\"日志实例启动失败\\n\")\n",
    "        return\n",
    "    \n",
    "    def Save(self,path_list:list):\n",
    "        for path in path_list:\n",
    "            if os.path.exists(path):\n",
    "                file_name = os.path.basename(path)\n",
    "                copy_file_to_dir(file_name,f\"{self.__location}/{self.__runid}/files/\")\n",
    "                with open(f\"{self.__location}/{self.__runid}/file.tag\",\"a\") as f:\n",
    "                    f.write(f\"files/{file_name}\\n\")\n",
    "                    f.flush()\n",
    "        return\n",
    "        \n",
    "    def Run(self) ->None:\n",
    "\n",
    "        os.makedirs(f\"{self.__location}/{self.__runid}\",exist_ok=True)\n",
    "\n",
    "        with open(f\"{self.__location}/{self.__runid}/start.tag\",mode=\"w\") as f:\n",
    "            f.write(f\"{format_time()} | {self.__runid}\\n\")\n",
    "            f.flush()\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #通知客户端开始\n",
    "        send_data ={\n",
    "                        \"experimentId\":self.__config[\"experiment_id\"],\n",
    "                        \"runName\": self.__runid,\n",
    "                        \"status\": 0\n",
    "                    }\n",
    "        \n",
    "        resp = api(url=self.__api_notice_run,data=send_data)\n",
    "        if not resp[\"code\"] == 200:\n",
    "            raise ConnectionError\n",
    "\n",
    "        self.__watcher()\n",
    "            \n",
    "        return\n",
    "\n",
    "    def Log(self,info:dict) ->None:\n",
    "        try:\n",
    "            self.__trainning_status[\"count\"] += 1\n",
    "            self.__trainning_status[\"epoch\"].append(info)\n",
    "        except:\n",
    "            raise BaseException(\"Epoch日志采集失败\")\n",
    "        return \n",
    "    \n",
    "    def End(self) ->None:\n",
    "\n",
    "        \n",
    "        send_data ={\n",
    "                        \"experimentId\":self.__config[\"experiment_id\"],\n",
    "                        \"runName\": self.__runid,\n",
    "                        \"status\": 1\n",
    "                    }\n",
    "        resp = api(url=self.__api_notice_run,data=send_data)\n",
    "        if not resp[\"code\"] == 200:\n",
    "            raise ConnectionError\n",
    "        result_path =f\"{self.__location}/{self.__runid}/results.json\"\n",
    "        save_dict_to_json(self.__trainning_status[\"epoch\"][self.__trainning_status[\"next_start_at\"]:self.__trainning_status[\"count\"]],result_path)\n",
    "        result_csv_path=f\"{self.__location}/{self.__runid}/results.csv\"\n",
    "\n",
    "        dict = quick_analysis(status=self.__trainning_status[\"epoch\"][self.__trainning_status[\"next_start_at\"]:self.__trainning_status[\"count\"]])\n",
    "        analysis_json_path = f\"{self.__location}/{self.__runid}/analysis.json\"\n",
    "        analysis_yaml_path = f\"{self.__location}/{self.__runid}/analysis.yaml\"\n",
    "        save_dict_to_json(dict,analysis_json_path)\n",
    "        save_dict_to_yaml(dict,analysis_yaml_path)\n",
    "\n",
    "        save_list_to_csv(self.__trainning_status[\"epoch\"][self.__trainning_status[\"next_start_at\"]:self.__trainning_status[\"count\"]],result_csv_path)\n",
    "        self.__trainning_status[\"next_start_at\"] = self.__trainning_status[\"count\"]\n",
    "        last = self.__trainning_status[\"epoch\"][len(self.__trainning_status[\"epoch\"])-1]\n",
    "        last_result_path = f\"{self.__location}/{self.__runid}/last.json\"\n",
    "        save_dict_to_json(last,last_result_path)\n",
    "\n",
    "\n",
    "        self.__kill_watcher()\n",
    "\n",
    "        i=0\n",
    "        while os.path.exists(f\"{self.__location}/run-{i}\"):\n",
    "            i+=1   \n",
    "        with open(f\"{self.__location}/{self.__runid}/finish.tag\",mode=\"a\") as f:\n",
    "            f.write(f\"{format_time()} | {self.__runid} \\n\")\n",
    "            f.flush()     \n",
    "        self.__runid = f\"run-{i}\"\n",
    "        return\n",
    "    \n",
    "    def __kill_watcher(self):\n",
    "        self.__watcher_cpu.kill()\n",
    "        self.__watcher_gpu.kill()\n",
    "        return\n",
    "    \n",
    "    def Submit(self) ->None:\n",
    "        try:\n",
    "            send_data = {\n",
    "                            \"experimentId\":self.__config[\"experiment_id\"],\n",
    "                            \"status\":1\n",
    "                        }\n",
    "\n",
    "            resp = api(url=self.__api_notice_experiment,data=send_data)\n",
    "            if not resp[\"code\"] == 200:\n",
    "                raise ConnectionError\n",
    "\n",
    "            # result_csv_path = f\"{self.__location}/result.csv\"\n",
    "            # save_list_to_csv(self.__trainning_status[\"epoch\"],result_csv_path)\n",
    "\n",
    "            dict = quick_analysis(status=self.__trainning_status[\"epoch\"])\n",
    "            analysis_json_path = f\"{self.__location}/analysis.json\"\n",
    "            analysis_yaml_path = f\"{self.__location}/analysis.yaml\"\n",
    "            save_dict_to_json(dict,analysis_json_path)\n",
    "            save_dict_to_yaml(dict,analysis_yaml_path)\n",
    "            \n",
    "            with open(f\"{self.__location}/finish.tag\",mode=\"a\") as f:\n",
    "                f.write(f\"{format_time()} | finish \\n\")\n",
    "                f.flush() \n",
    "\n",
    "        except:\n",
    "            raise BaseException(\"END ERROR\")\n",
    "        return\n",
    "    \n",
    "    def __save_config(self) ->None:\n",
    "        try:\n",
    "            config_path_json = self.__location +\"/\"+\"config.json\"\n",
    "            save_dict_to_json(self.__config,config_path_json)\n",
    "            config_path_yaml = self.__location +\"/\"+\"config.yaml\"\n",
    "            save_dict_to_yaml(self.__config,config_path_yaml)\n",
    "        except:\n",
    "            raise BaseException(\"保存配置信息失败 \\n\")\n",
    "        return\n",
    "\n",
    "    def __save_code(self,path=[\"datasets\"])->None:\n",
    "        ignore_path = [*path]\n",
    "        try:\n",
    "            if os.path.exists(\".path_ignore\"):\n",
    "                with open(\".path_ignore\") as f:\n",
    "                    line =  f.readline()\n",
    "                    while line:\n",
    "                        ignore_path.append(line.strip())\n",
    "                        line = f.readline()\n",
    "            shutil.copytree(src=self.__codedir,dst=self.__savedir,dirs_exist_ok=True,ignore=shutil.ignore_patterns(*ignore_path))\n",
    "        except:\n",
    "            raise BaseException(\"备份代码失败 \\n\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-31 15:59:03 {'userToken': 'eyJhbGciOiJIUzI1NiIsInppcCI6IkdaSVAifQ.H4sIAAAAAAAAAKtWKi5NUrJS8kotcSwtyff1UdJRSq0oULIyNLO0MLMwNDMw0FEqLU4t8kwBipkDRS0NTA0sjA2NjQxNLM0tIJJ-ibmpQEMyShPz0itKU_Lz0pVqAV0AZlNaAAAA.IsqnyZC_OLIU-jTzEJ1QSfrVD7efzmKAxCaLq2bvQf0', 'projectId': '907', 'description': 'description ， 111', 'experimentName': 'experiment_name 111-20231031155903', 'repositoryId': 'e4107e9add2646d9b85a6a4c9fa43136'} http://127.0.0.1:5560/ml_client/client/loadSavePath\n",
      "2023-10-31 15:59:03 {'msg': '操作成功', 'code': 200, 'data': '/opt/jml_ai_result'} \n",
      "2023-10-31 15:59:06 {'experimentId': '883033828197842', 'status': 0} http://127.0.0.1:5560/ml_client/client/noticeExperiment\n",
      "2023-10-31 15:59:06 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n",
      "2023-10-31 15:59:06 {'experimentId': '883033828197842', 'runName': 'run-0', 'status': 0} http://127.0.0.1:5560/ml_client/client/noticeRun\n",
      "2023-10-31 15:59:06 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n",
      "2023-10-31 16:00:41 {'experimentId': '883033828197842', 'runName': 'run-0', 'status': 1} http://127.0.0.1:5560/ml_client/client/noticeRun\n",
      "2023-10-31 16:00:41 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n",
      "2023-10-31 16:00:41 {'experimentId': '883033828197842', 'runName': 'run-1', 'status': 0} http://127.0.0.1:5560/ml_client/client/noticeRun\n",
      "2023-10-31 16:00:41 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n",
      "2023-10-31 16:02:10 {'experimentId': '883033828197842', 'runName': 'run-1', 'status': 1} http://127.0.0.1:5560/ml_client/client/noticeRun\n",
      "2023-10-31 16:02:10 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n",
      "2023-10-31 16:02:10 {'experimentId': '883033828197842', 'runName': 'run-2', 'status': 0} http://127.0.0.1:5560/ml_client/client/noticeRun\n",
      "2023-10-31 16:02:10 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n",
      "2023-10-31 16:03:39 {'experimentId': '883033828197842', 'runName': 'run-2', 'status': 1} http://127.0.0.1:5560/ml_client/client/noticeRun\n",
      "2023-10-31 16:03:39 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n",
      "2023-10-31 16:03:39 {'experimentId': '883033828197842', 'status': 1} http://127.0.0.1:5560/ml_client/client/noticeExperiment\n",
      "2023-10-31 16:03:39 {'msg': '操作成功', 'code': 200, 'data': '操作成功'} \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#定义示例模型\n",
    "class CNN(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(CNN,self).__init__()\n",
    "\n",
    "            self.conv1=nn.Sequential(\n",
    "                nn.Conv2d(              \n",
    "                    in_channels=1,    \n",
    "                    out_channels=16,    \n",
    "                    kernel_size=5,      \n",
    "                    stride=1,          \n",
    "                    padding=2,          \n",
    "                ),    \n",
    "                nn.ReLU(),              \n",
    "                nn.MaxPool2d(kernel_size=2),    \n",
    "            )\n",
    "\n",
    "            self.conv2=nn.Sequential(\n",
    "                nn.Conv2d(              \n",
    "                    in_channels=16,    \n",
    "                    out_channels=32,    \n",
    "                    kernel_size=5,      \n",
    "                    stride=1,           \n",
    "                    padding=2,          \n",
    "                ),                      \n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),    \n",
    "            )\n",
    "\n",
    "            self.out=nn.Linear(32*7*7,10)      \n",
    "\n",
    "        def forward(self,x):\n",
    "            x=self.conv1(x)\n",
    "            x=self.conv2(x)     \n",
    "            x=x.view(x.size(0),-1)    \n",
    "            output=self.out(x)\n",
    "            \n",
    "            return output\n",
    "\n",
    "#Hyper prameters\n",
    "EPOCH=3\n",
    "BATCH_SIZE=64\n",
    "LR=0.001\n",
    "DOWNLOAD_MNIST=False\n",
    "\n",
    "log = NewLogger(\n",
    "\n",
    "    conf={\n",
    "    'access_token':\"eyJhbGciOiJIUzI1NiIsInppcCI6IkdaSVAifQ.H4sIAAAAAAAAAKtWKi5NUrJS8kotcSwtyff1UdJRSq0oULIyNLO0MLMwNDMw0FEqLU4t8kwBipkDRS0NTA0sjA2NjQxNLM0tIJJ-ibmpQEMyShPz0itKU_Lz0pVqAV0AZlNaAAAA.IsqnyZC_OLIU-jTzEJ1QSfrVD7efzmKAxCaLq2bvQf0\",\n",
    "    'project':\"907\", \n",
    "    \"description\":\"description ， 111\",\n",
    "    \"experiment_name\":\"experiment_name 111\",\n",
    "    \"repository_id\":\"e4107e9add2646d9b85a6a4c9fa43136\"\n",
    "    },\n",
    "\n",
    "    info={\n",
    "    \"learnning_rate\":LR,\n",
    "    \"epoch\":EPOCH,\n",
    "    \"batch_size\":BATCH_SIZE\n",
    "    }\n",
    "    \n",
    ")\n",
    "\n",
    "run_count = 0\n",
    "while run_count<3:\n",
    "\n",
    "    log.Run()\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\") \n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "    train_data=torchvision.datasets.MNIST(\n",
    "        root='./mnist',\n",
    "        train=True,\n",
    "        transform=torchvision.transforms.ToTensor(),    \n",
    "        download=DOWNLOAD_MNIST\n",
    "    )\n",
    "\n",
    "    train_loader=Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    test_data=torchvision.datasets.MNIST(\n",
    "        root='./mnist',\n",
    "        train=False,\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        test_x=Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.cuda.FloatTensor)[:2000]/255  \n",
    "        test_y=test_data.targets[:2000]\n",
    "        test_y.cuda()\n",
    "\n",
    "\n",
    "            \n",
    "    cnn=CNN()\n",
    "    cnn.to(device=device)\n",
    "\n",
    "    optimizer=torch.optim.Adam(cnn.parameters(),lr=LR)\n",
    "    loss_fn=nn.CrossEntropyLoss()\n",
    "\n",
    "    step=0\n",
    "    for e in range(EPOCH):\n",
    "        #加载训练数据\n",
    "        for step,(x,y) in enumerate(train_loader):\n",
    "            \n",
    "            b_x=Variable(x.to(device))\n",
    "            b_y=Variable(y.to(device))\n",
    "            output=cnn(b_x)         \n",
    "            loss=loss_fn(output,b_y)\n",
    "            optimizer.zero_grad()   \n",
    "            loss.backward()         \n",
    "            optimizer.step()        \n",
    "\n",
    "            count = 1\n",
    "            #每执行count次，输出一下当前epoch、loss、accuracy\n",
    "            if (step%count==0):\n",
    "                #计算模型预测正确率\n",
    "                test_output=cnn(test_x)\n",
    "                y_pred=torch.max(test_output,1)[1].data.squeeze()\n",
    "                accuracy=sum(y_pred==test_y.cuda()).item()/test_y.cuda().size(0)\n",
    "               \n",
    "                log.Log({\"epoch\":e,\"loss\":loss.item(),\"accuracy\":accuracy})\n",
    "                \n",
    "                log.Save([\"1.png\"])\n",
    "                \n",
    "                # print('now epoch :  ', epoch, '   |  loss : %.4f ' % loss.item(), '     |   accuracy :   ' , accuracy)\n",
    "        model_path = \"model.pt\"\n",
    "        torch.save(cnn,model_path)\n",
    "        \n",
    "        # 3.6 3.8 3.10 后面继续扩充版本，记录变化\n",
    "        # cuda：支持兼容版本\n",
    "        # 支持 torch \n",
    "        # mac 回去测试 win11 ubuntu20/22\n",
    "        #\n",
    "        \n",
    "        #文件记录接口\n",
    "        log.Save([model_path])\n",
    "\n",
    "    test_output=cnn(test_x[:10])\n",
    "    y_pred=torch.max(test_output,1)[1].data.squeeze()       \n",
    "    log.Print(f\"预测值: {y_pred.tolist()}\")\n",
    "    log.Print(f\"实际值: {test_y[:10].tolist()}\")\n",
    "    \n",
    "    log.End()\n",
    "    run_count +=1\n",
    "\n",
    "log.Submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
